---
layout: default
title: 2_03_íŠ¹ì„±ê³µí•™ê³¼ ê·œì œ_ê°œì¸í•™ìŠµ
parent: AI ê¸°ì´ˆ
grand_parent: AI
nav_order: 6
---
# ì˜ˆì œëŠ” ë°•í•´ì„ ë‹˜ì˜ í˜¼ì ê³µë¶€í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹+ë”¥ëŸ¬ë‹ì„ ì°¸ì¡°í–ˆìŠµë‹ˆë‹¤. ë°•í•´ì„ ë‹˜ê»˜ ë§ˆìŒì† ê¹Šì´ ê°ì‚¬ë“œë¦½ë‹ˆë‹¤.
# ì‹œë‚˜ë¦¬ì˜¤
- ë‹¤í•­íšŒê·€ë¡œ ë†ì–´ì˜ ë¬´ê²Œë¥¼ ì˜ˆì¸¡í•  ìˆ˜ ìˆìŒ
- í›ˆë ¨ë°ì´í„°ì…‹ë³´ë‹¤ í…ŒìŠ¤íŠ¸ë°ì´í„°ì…‹ì˜ í‰ê°€ì ìˆ˜ê°€ ë†’ì€ ê²ƒì´ ë¬¸ì œë¡œ ë³´ì„
- ë‘ ë²ˆì§¸ íŠ¹ì„±ìœ¼ë¡œ ê¸¸ì´ì˜ ì œê³± ëŒ€ì‹  ë‹¤ë¥¸ ê³ ì°¨í•­ì„ ë„£ì–´ì•¼ í•  ê²ƒìœ¼ë¡œ ìƒê°ë¨

### í•´ê²°ë°©ë²•
- í˜„ì¬ ë°ì´í„°ë¥¼ í™•ì¸í•˜ë©´ ë†’ì´ì™€ ë‘ê»˜ì •ë³´ë„ ìˆìŒ
- ì„ í˜•íšŒê·€ëŠ” íŠ¹ì„±ì´ ë§ì„ìˆ˜ë¡ íš¨ê³¼ê°€ ì¢‹ìŒ
- ì¤€ë¹„ëœ ë°ì´í„° ëª¨ë‘(ë†’ì´ì™€ ë‘ê»˜)ë¥¼ ì‚¬ìš©í•˜ë„ë¡ í•œë‹¤.


# ë‹¤ì¤‘íšŒê·€(Multiple Regression)
- 2ê°œ ì´ìƒì˜ íŠ¹ì„±ì„ ì´ìš©í•˜ëŠ” íšŒê·€ ë¶„ì„

### ì°¨ì› ê°œë…
- 1ê°œì˜ íŠ¹ì„±ì„ ì‚¬ìš©í•˜ë©´ ì§ì„ 
- 2ê°œì˜ íŠ¹ì„±ì„ ì‚¬ìš©í•˜ë©´ í‰ë©´(ê³¡ì„ )
- 3ê°œì˜ íŠ¹ì„±ì„ ì‚¬ìš©í•˜ë©´ 3ì°¨ì›(í‘œí˜„ì´ ì–´ë ¤ì›€)
    - $y = W_1 \times íŠ¹ì„±_1 + W_2 \times íŠ¹ì„±_2 + W_3 \times íŠ¹ì„±_3 + b$

- ì°¨ì›ì´ ë†’ë‹¤ê³ í•˜ì—¬ íšŒê·€ë¶„ì„ì´ ì•ˆì¢‹ì€ ê²ƒì´ ì•„ë‹˜
- ë†’ì€ ì°¨ì›ì„ ì´ìš©í•˜ëŠ” ê²½ìš° ë§¤ìš° ë³µì¡í•œ ëª¨ë¸ë„ í‘œí˜„ì´ ê°€ëŠ¥í•¨

### íŠ¹ì„± ê³µí•™(Feature Engineering)
- ê¸°ì¡´ì˜ íŠ¹ì„±ì„ ì‚¬ìš©í•˜ì—¬ ìƒˆë¡œìš´ íŠ¹ì„±ì„ ë½‘ì•„ë‚´ëŠ” ê²ƒì„ ë§í•¨

#### ë°ì´í„° ì¤€ë¹„


```python
from google.colab import drive
drive.mount('/content/drive')
```

    Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount("/content/drive", force_remount=True).
    


```python
import pandas as pd
df = pd.read_csv('/content/drive/MyDrive/NEW/1week/02_á„’á…¬á„€á…±á„‹á…ª á„†á…©á„ƒá…¦á†¯á„€á…²á„Œá…¦(á„‹á…§á†«á„‰á…³á†¸)/perch_csv_data.csv')
perch_full = df.to_numpy()
print(perch_full[:5])
```

    [[ 8.4   2.11  1.41]
     [13.7   3.53  2.  ]
     [15.    3.82  2.43]
     [16.2   4.59  2.63]
     [17.4   4.59  2.94]]
    


```python
from sklearn.datasets import load_wine

load_wine = load_wine()
load_wine
load_wine["feature_names"]
```




    ['alcohol',
     'malic_acid',
     'ash',
     'alcalinity_of_ash',
     'magnesium',
     'total_phenols',
     'flavanoids',
     'nonflavanoid_phenols',
     'proanthocyanins',
     'color_intensity',
     'hue',
     'od280/od315_of_diluted_wines',
     'proline']



#### ê¸°ì¡´ íƒ€ì¼“(y) ë°ì´í„°


```python
import numpy as np

perch_weight = np.array(
    [5.9, 32.0, 40.0, 51.5, 70.0, 100.0, 78.0, 80.0, 85.0, 85.0,
     110.0, 115.0, 125.0, 130.0, 120.0, 120.0, 130.0, 135.0, 110.0,
     130.0, 150.0, 145.0, 150.0, 170.0, 225.0, 145.0, 188.0, 180.0,
     197.0, 218.0, 300.0, 260.0, 265.0, 250.0, 250.0, 300.0, 320.0,
     514.0, 556.0, 840.0, 685.0, 700.0, 700.0, 690.0, 900.0, 650.0,
     820.0, 850.0, 900.0, 1015.0, 820.0, 1100.0, 1000.0, 1100.0,
     1000.0, 1000.0]
     )
```

#### ë°ì´í„° ë¶„í• 


```python
from sklearn.model_selection import train_test_split

train_input, test_input, train_target, test_target = train_test_split(perch_full, perch_weight, random_state=42)
```

#### ë‹¤ì¤‘ ì„ í˜• íšŒê·€ ì ìš©


```python
from sklearn.linear_model import LinearRegression

lr = LinearRegression()
lr.fit(train_input, train_target)

print(lr.score(train_input, train_target))
print(lr.score(test_input, test_target))
```

    0.9559326821885706
    0.8796419177546366
    

##### í•´ì„
- ê¸¸ì´, ë†’ì´, ë‘ê»˜ë¥¼ ëª¨ë‘ ì‚¬ìš©
- í›ˆë ¨ë°ì´í„° ì ìˆ˜ê°€ ë†’ê³  í…ŒìŠ¤íŠ¸ ë°ì´í„° ì ìˆ˜ê°€ ê½¤ ì°¨ì´ê°€ ìˆì–´ ê³¼ëŒ€ì í•©ìœ¼ë¡œ ë³´ì„

# ì‚¬ì´í‚·ëŸ°ì—ì„œ ì œê³µí•˜ëŠ” ë³€í™˜ê¸°(transformer)
### ì‚¬ì´í‚·ëŸ°ì—ì„œëŠ” íŠ¹ì„±ì„ ë§Œë“¤ê±°ë‚˜ ì „ì²˜ë¦¬ ì‘ì—…ì„ ìœ„í•œ ë‹¤ì–‘í•œ í´ë˜ìŠ¤ ì œê³µ
#### ì‚¬ì´í‚·ëŸ° ëª¨ë¸(estimator) í´ë˜ìŠ¤ì—ì„œ ì œê³µí•˜ëŠ” ì¼ê´€ëœ ëª©ì ì˜ í•¨ìˆ˜
- fit()
- score()
- predict()

#### ë³€í™˜ê¸°(transformer) í´ë˜ìŠ¤ì—ì„œ ì œê³µí•˜ëŠ” ì¼ê´€ëœ ëª©ì ì˜ í•¨ìˆ˜
- fit()
- transform()
- fit_transform()

### ì‚¬ì´í‚·ëŸ°ì˜ PolynomialFeatures í´ë˜ìŠ¤ í™œìš©
- from sklearn.preprocessing import PolynomialFeatures


```python
from sklearn.preprocessing import PolynomialFeatures

poly = PolynomialFeatures()
poly.fit([[4,23]])
print(poly.transform([[4,3]]))
```

    [[ 1.  4.  3. 16. 12.  9.]]
    

##### ê²°ê³¼ ì„¤ëª…
- fit()ë©”ì„œë“œëŠ” ìƒˆë¡œ ë§Œë“¤ íŠ¹ì„± ì¡°í•©ì„ ì°¾ìŒ
- transform()ë©”ì„œë“œëŠ” ì‹¤ì œë¡œ ë°ì´í„°ë¥¼ ë³€í™˜
- fit()ë©”ì„œë“œì—ëŠ” ì…ë ¥ë°ì´í„°ë§Œ ì „ë‹¬
- 2, 3ì„ ê°€ì§€ê³  6ê°œì˜ íŠ¹ì„±ë°ì´í„°ë¥¼ ìƒì„±í•œ ê²ƒ

#### PolynomialFeaturesí´ë˜ìŠ¤ì˜ ê¸°ëŠ¥
- ê° íŠ¹ì„±ì„ ì œê³±í•œ í•­ì„ ì¶”ê°€(2, 3ì„ ì œê³±í•œ 4, 9 ì¶”ê°€)
- íŠ¹ì„±ë¼ë¦¬ ê³±í•œ í•­ì„ ì¶”ê°€(2, 3ì„ ê³±í•œ 6 ì¶”ê°€)
- ë§ˆì§€ë§‰ì— ì„ í˜• ë°©ì •ì‹ì˜ ì ˆí¸ì„ í•­ìƒ 1ì¸ íŠ¹ì„±ê³¼ ê³±í•´ì§€ëŠ” ê³„ìˆ˜ë¡œ ë³¼ ìˆ˜ ìˆë‹¤.
    - $ë¬´ê²Œ = W_1 \times íŠ¹ì„±1(ê¸¸ì´) + W_2 \times íŠ¹ì„±2(ë†’ì´) + W_3 \times íŠ¹ì„±3(ë‘ê»˜) \times 1$
    
- ì‚¬ì´í‚·ëŸ°ì˜ ì„ í˜• ëª¨ë¸ì€ ìë™ìœ¼ë¡œ ì ˆí¸ì„ ì¶”ê°€í•˜ë¯€ë¡œ 1ì€ ì œì™¸í•˜ë„ë¡ í•œë‹¤.


```python
from sklearn.preprocessing import PolynomialFeatures

poly = PolynomialFeatures(include_bias=False) # ê³„ìˆ˜(1) ì¶”ê°€ ì•ˆ í•¨
poly.fit([[2,3]])
print(poly.transform([[2,3]]))
```

    [[2. 3. 4. 6. 9.]]
    


```python
from sklearn.preprocessing import PolynomialFeatures

poly = PolynomialFeatures(include_bias=False) # ê³„ìˆ˜(1) ì¶”ê°€ ì•ˆ í•¨
poly.fit([[2,3,4]])
print(poly.transform([[2,3,4]]))
```

    [[ 2.  3.  4.  4.  6.  8.  9. 12. 16.]]
    


```python
from sklearn.preprocessing import PolynomialFeatures

# í›ˆë ¨ë°ì´í„°ì…‹(train_input)ì— ë³€í™˜ê¸° ì ìš©
poly = PolynomialFeatures(include_bias=False) # ê³„ìˆ˜(1) ì¶”ê°€ ì•ˆ í•¨
poly.fit(train_input)
train_poly = poly.transform(train_input)
train_poly[:5] # ì¶”ê°€ëœ íŠ¹ì„± í™•ì¸
```




    array([[  19.6   ,    5.14  ,    3.04  ,  384.16  ,  100.744 ,   59.584 ,
              26.4196,   15.6256,    9.2416],
           [  22.    ,    5.88  ,    3.52  ,  484.    ,  129.36  ,   77.44  ,
              34.5744,   20.6976,   12.3904],
           [  18.7   ,    5.2   ,    3.12  ,  349.69  ,   97.24  ,   58.344 ,
              27.04  ,   16.224 ,    9.7344],
           [  17.4   ,    4.59  ,    2.94  ,  302.76  ,   79.866 ,   51.156 ,
              21.0681,   13.4946,    8.6436],
           [  36.    ,   10.61  ,    6.74  , 1296.    ,  381.96  ,  242.64  ,
             112.5721,   71.5114,   45.4276]])




```python
train_input[:5]
```




    array([[19.6 ,  5.14,  3.04],
           [22.  ,  5.88,  3.52],
           [18.7 ,  5.2 ,  3.12],
           [17.4 ,  4.59,  2.94],
           [36.  , 10.61,  6.74]])




```python
print(train_poly.shape)
```

    (42, 9)
    

#### ìƒˆë¡œ ìƒì„±ëœ íŠ¹ì„±ì´ ì–´ë–»ê²Œ ë§Œë“¤ì–´ì¡ŒëŠ”ì§€ í™•ì¸


```python
poly.get_feature_names_out()
```




    array(['x0', 'x1', 'x2', 'x0^2', 'x0 x1', 'x0 x2', 'x1^2', 'x1 x2',
           'x2^2'], dtype=object)



- 'x0': ì²« ë²ˆì§¸ íŠ¹ì„±
- 'x0^2' : ì²« ë²ˆì§¸ íŠ¹ì„±ì— ì œê³±
- 'x0 x1' : ë‘ íŠ¹ì„±ì˜ ê³±

#### fitëœ ë°©ì‹ìœ¼ë¡œ testë°ì´í„°ë„ ë³€í™˜


```python
test_poly = poly.transform(test_input)
```


```python
test_input[:5]
```




    array([[ 8.4 ,  2.11,  1.41],
           [18.  ,  5.22,  3.32],
           [27.5 ,  7.28,  4.57],
           [21.3 ,  6.38,  3.53],
           [22.5 ,  5.86,  3.62]])




```python
test_poly[:5]
```




    array([[  8.4   ,   2.11  ,   1.41  ,  70.56  ,  17.724 ,  11.844 ,
              4.4521,   2.9751,   1.9881],
           [ 18.    ,   5.22  ,   3.32  , 324.    ,  93.96  ,  59.76  ,
             27.2484,  17.3304,  11.0224],
           [ 27.5   ,   7.28  ,   4.57  , 756.25  , 200.2   , 125.675 ,
             52.9984,  33.2696,  20.8849],
           [ 21.3   ,   6.38  ,   3.53  , 453.69  , 135.894 ,  75.189 ,
             40.7044,  22.5214,  12.4609],
           [ 22.5   ,   5.86  ,   3.62  , 506.25  , 131.85  ,  81.45  ,
             34.3396,  21.2132,  13.1044]])



#### ë‹¤ì¤‘íšŒê·€ëª¨ë¸ í›ˆë ¨


```python
from sklearn.linear_model import LinearRegression

lr = LinearRegression()
lr.fit(train_poly, train_target)
```









```python
print(lr.score(train_poly, train_target))
print(lr.score(test_poly, test_target))
```

    0.9903183436982125
    0.9714559911594111
    

##### ê²°ê³¼
- ì ìˆ˜ê°€ ë†’ê²Œ ë‚˜ì™”ìŒ
- ë†ì–´ì˜ ê¸¸ì´, ë†’ì´, ë‘ê»˜ ëª¨ë‘ë¥¼ ì‚¬ìš©í•¨
- ê° íŠ¹ì„±ì„ ì œê³±í•˜ê±°ë‚˜ ì„œë¡œ ê³±í•˜ì—¬ ë‹¤í•­ì ì¸ íŠ¹ì„±ì„ ì¶”ê°€í•¨
- íŠ¹ì„±ì´ ëŠ˜ì–´ë‚˜ë©´ ì„ í˜•íšŒê·€ì˜ ì˜ˆì¸¡ ê²°ê³¼ê°€ ë†’ì•„ì§


- í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•œ ì ìˆ˜ëŠ” ë†’ì•„ì§€ì§€ ì•Šì•˜ìŒ
- ë†ì–´ì˜ ê¸¸ì´ë§Œ ì‚¬ìš©í•œ ê²°ê³¼ì˜ ê³¼ì†Œì í•©ì´ í•´ì†Œëœ ê²ƒìœ¼ë¡œ ë³´ì—¬ì§

#### íŠ¹ì„±ì„ ë” ë§ì´ ëŠ˜ë¦¬ë©´?
- 3ì„¸ê³±, 4ì œê³± ë“±ì˜ í•­ì„ ë„£ì–´ë³¸ë‹¤.
- degreeì˜µì…˜ : ê³ ì°¨í•­ì˜ ìµœëŒ€ì°¨ìˆ˜


```python
poly = PolynomialFeatures(degree=5, include_bias=False)

poly.fit(train_input)
train_poly = poly.transform(train_input)
test_poly = poly.transform(test_input)
```


```python
print(train_poly[:1])
print(test_poly[:1])
```

    [[1.96000000e+01 5.14000000e+00 3.04000000e+00 3.84160000e+02
      1.00744000e+02 5.95840000e+01 2.64196000e+01 1.56256000e+01
      9.24160000e+00 7.52953600e+03 1.97458240e+03 1.16784640e+03
      5.17824160e+02 3.06261760e+02 1.81135360e+02 1.35796744e+02
      8.03155840e+01 4.75018240e+01 2.80944640e+01 1.47578906e+05
      3.87018150e+04 2.28897894e+04 1.01493535e+04 6.00273050e+03
      3.55025306e+03 2.66161618e+03 1.57418545e+03 9.31035750e+02
      5.50651494e+02 6.97995264e+02 4.12822102e+02 2.44159375e+02
      1.44405545e+02 8.54071706e+01 2.89254655e+06 7.58555575e+05
      4.48639873e+05 1.98927329e+05 1.17653518e+05 6.95849599e+04
      5.21676772e+04 3.08540347e+04 1.82483007e+04 1.07927693e+04
      1.36807072e+04 8.09131319e+03 4.78552376e+03 2.83034868e+03
      1.67398054e+03 3.58769566e+03 2.12190560e+03 1.25497919e+03
      7.42244501e+02 4.38992857e+02 2.59637799e+02]]
    [[8.40000000e+00 2.11000000e+00 1.41000000e+00 7.05600000e+01
      1.77240000e+01 1.18440000e+01 4.45210000e+00 2.97510000e+00
      1.98810000e+00 5.92704000e+02 1.48881600e+02 9.94896000e+01
      3.73976400e+01 2.49908400e+01 1.67000400e+01 9.39393100e+00
      6.27746100e+00 4.19489100e+00 2.80322100e+00 4.97871360e+03
      1.25060544e+03 8.35712640e+02 3.14140176e+02 2.09923056e+02
      1.40280336e+02 7.89090204e+01 5.27306724e+01 3.52370844e+01
      2.35470564e+01 1.98211944e+01 1.32454427e+01 8.85122001e+00
      5.91479631e+00 3.95254161e+00 4.18211942e+04 1.05050857e+04
      7.01998618e+03 2.63877748e+03 1.76335367e+03 1.17835482e+03
      6.62835771e+02 4.42937648e+02 2.95991509e+02 1.97795274e+02
      1.66498033e+02 1.11261719e+02 7.43502481e+01 4.96842890e+01
      3.32013495e+01 4.18227202e+01 2.79478841e+01 1.86760742e+01
      1.24802202e+01 8.33986280e+00 5.57308367e+00]]
    


```python
print(train_poly.shape)
```

    (42, 55)
    


```python
lr.fit(train_poly, train_target)
print(lr.score(train_poly, train_target))
print(lr.score(test_poly, test_target))
```

    0.9999999999996433
    -144.40579436844948
    

#### ê²°ê³¼ ì„¤ëª…
- ë§Œë“¤ì–´ì§„ íŠ¹ì„±ì˜ ê°œìˆ˜ê°€ 55ê°œ
- í›ˆë ¨ ë°ì´í„°ì…‹ì— ëŒ€í•œ ì ìˆ˜ëŠ” ì™„ë²½ì— ê°€ê¹Œì›€
- í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì— ëŒ€í•œ ì ìˆ˜ëŠ” <b>ê³¼ëŒ€ ì í•©</b> ë¬¸ì œ ë°œìƒ

# ì‹œë‚˜ë¦¬ì˜¤
### ìƒ˜í”Œì˜ ê°œìˆ˜ë³´ë‹¤ íŠ¹ì„±ì´ ë” ë§ì€ ìƒí™©
- 42ê°œì˜ ìƒ˜í”Œì´ ìˆëŠ”ë° íŠ¹ì„±ì´ ì´ë³´ë‹¤ ë§ìŒ(55ê°œ)
- 42ê°œì˜ ìˆ«ì ì¤‘ í•œ ë²ˆì˜ ì„ íƒìœ¼ë¡œ ê°’ì„ ë§ì¶”ëŠ” ê²ƒì€ ì–´ë µë‹¤.
- 42ê°œì˜ ìˆ«ì ì¤‘ 55ë²ˆ ì„ íƒí•´ì„œ ê°’ì„ ë§ì¶”ëŠ” ê²ƒì€ ë§¤ìš° ì‰½ë‹¤.
- ì´ ê²½ìš° íŠ¹ì„±ì„ ë‹¤ì‹œ ì¤„ì´ëŠ” ê²ƒì´ í•„ìš”

# ê·œì œ(Regularization)
- ê³¼ëŒ€ì í•©ì„ í•´ì†Œí•˜ëŠ” ë°©ë²•
- ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì´ í›ˆë ¨ ë°ì´í„°ì…‹ì„ ë„ˆë¬´ ê³¼ë„í•˜ê²Œ í•™ìŠµí•˜ì§€ ëª»í•˜ë„ë¡ ì œì–´í•˜ëŠ” ê²ƒ
- íŠ¹ì„±ì— ê³±í•´ì§€ëŠ” ê³„ìˆ˜(ë˜ëŠ” ê¸°ìš¸ê¸°)ì˜ í¬ê¸°ë¥¼ ì‘ê²Œ ë§Œë“œëŠ” ê²ƒ


#### 55ê°œì˜ íŠ¹ì„±ìœ¼ë¡œ í›ˆë ¨í•œ ì„ í˜•íšŒê·€ëª¨ë¸ì˜ ê³„ìˆ˜ë¥¼ ê·œì œ
- í›ˆë ¨ ë°ì´í„°ì…‹ì˜ ì ìˆ˜ë¥¼ ë‚®ì¶”ê³  í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì˜ ì ìˆ˜ë¥¼ ë†’ì—¬ë³¸ë‹¤.

#### íŠ¹ì„± ìŠ¤ì¼€ì¼ë§(Feature Scaling)
- ê³„ìˆ˜ì˜ í¬ê¸° ë¹„ìœ¨ì„ ë§ì¶”ëŠ” ê²ƒ
- íŠ¹ì„±1ì´ 1 ~ 10, íŠ¹ì„±2ê°€ 100 ~ 1000ì˜ ê°’ì„ ê°–ëŠ”ë‹¤ë©´ íŠ¹ì„±ê°„ ê°’ì˜ í¬ê¸° ì°¨ì´ë¡œ ë¬¸ì œ ë°œìƒ
- ì‚¬ì´í‚·ëŸ°ì—ì„œ ì œê³µí•˜ëŠ” StandardScaler í´ë˜ìŠ¤ ì‚¬ìš©(Normalization)
- í‘œì¤€í™”(Standardization)ì™€ ì •ê·œí™”(Normalization)ê°€ ìˆìŒ
    - ì´ìƒì¹˜ê°€ ìˆëŠ” ë°ì´í„°ê°€ ì•„ë‹ˆë¼ë©´ ì¼ë°˜ì ìœ¼ë¡œ ì •ê·œí™” ì§„í–‰


```python
from sklearn.preprocessing import StandardScaler

ss = StandardScaler()
ss.fit(train_poly) # í›ˆë ¨ ë°ì´í„°ë¡œ í•œë²ˆë§Œ fitì§„í–‰. í…ŒìŠ¤íŠ¸ ë°ì´í„°ëŠ” fitì´ ì•„ë‹Œ transformì„ ì ìš©

train_scaled = ss.transform(train_poly)
test_scaled = ss.transform(test_poly)
```


```python
# ìŠ¤ì¼€ì¼ë§ëœ í›ˆë ¨ë°ì´í„°ì…‹ê³¼ í…ŒìŠ¤íŠ¸ë°ì´í„°ì…‹ í™•ì¸
print(train_scaled[:1])
print(test_scaled[:1])
```

    [[-1.01339619 -1.01007487 -1.01952321 -0.9549757  -0.9496784  -0.95745849
      -0.93942079 -0.94342509 -0.94100107 -0.88757122 -0.88399964 -0.89100599
      -0.87785292 -0.88311456 -0.88430909 -0.8691891  -0.87259422 -0.87147928
      -0.86603533 -0.82233944 -0.82171953 -0.8280588  -0.81928269 -0.82512549
      -0.8278857  -0.81486775 -0.82006923 -0.82177279 -0.82010716 -0.80835934
      -0.81274154 -0.81321125 -0.8098514  -0.80275974 -0.7637909  -0.76597773
      -0.77150714 -0.76668667 -0.77246614 -0.77577893 -0.76571689 -0.77162398
      -0.77472752 -0.77517751 -0.76290623 -0.76877311 -0.77148634 -0.77113383
      -0.767785   -0.75814062 -0.76376113 -0.76586966 -0.76449499 -0.75967179
      -0.75143746]]
    [[-2.29657672 -2.0645632  -1.95288184 -1.55255604 -1.46585499 -1.45227925
      -1.38306012 -1.36853915 -1.3414385  -1.16487216 -1.12766176 -1.12993021
      -1.09096504 -1.0919529  -1.08681842 -1.05473034 -1.05422049 -1.04733556
      -1.03445922 -0.95097661 -0.93581382 -0.94095847 -0.92003743 -0.92481854
      -0.9257405  -0.90344054 -0.9076728  -0.90768173 -0.90365223 -0.88585964
      -0.88933355 -0.8882214  -0.88265495 -0.87279092 -0.82345261 -0.81922614
      -0.82441462 -0.81401521 -0.81951597 -0.82223805 -0.80760074 -0.81327179
      -0.81584326 -0.81548696 -0.79980303 -0.80545985 -0.80768359 -0.80657966
      -0.80223729 -0.79049072 -0.7959136  -0.79756241 -0.7954801  -0.78971903
      -0.78033726]]
    


```python
# StandardScalerì˜ í‰ê· 
print(ss.mean_)
```

    [2.84452381e+01 8.04238095e+00 4.82047619e+00 8.85315000e+02
     2.53486881e+02 1.51959000e+02 7.29365000e+01 4.36999452e+01
     2.62868381e+01 2.97326070e+04 8.59817581e+03 5.15200651e+03
     2.49680043e+03 1.49567194e+03 8.99184494e+02 7.27945149e+02
     4.36019840e+02 2.62115117e+02 1.58141990e+02 1.05917983e+06
     3.08429517e+05 1.84644673e+05 9.01239554e+04 5.39478286e+04
     3.23998082e+04 2.64224658e+04 1.58167367e+04 9.49991053e+03
     5.72489005e+03 7.77162422e+03 4.65285399e+03 2.79521756e+03
     1.68494739e+03 1.01911272e+03 3.93876111e+07 1.15192532e+07
     6.88842737e+06 3.37865413e+06 2.02034307e+06 1.21184517e+06
     9.93774754e+05 5.94291271e+05 3.56516573e+05 2.14541208e+05
     2.93110780e+05 1.75313851e+05 1.05196649e+05 6.33244641e+04
     3.82394901e+04 8.66870097e+04 5.18625239e+04 3.11308026e+04
     1.87477065e+04 1.13270112e+04 6.86569419e+03]
    


```python
# StandardScalerì˜ í‘œì¤€í¸ì°¨
print(ss.scale_)
```

    [8.72831196e+00 2.87343151e+00 1.74638123e+00 5.24782988e+02
     1.60836428e+02 9.64793789e+01 4.95165749e+01 2.97578956e+01
     1.81139412e+01 2.50155373e+04 7.49275582e+03 4.47153009e+03
     2.25433695e+03 1.34683566e+03 8.11988865e+02 6.81265335e+02
     4.07639942e+02 2.46263218e+02 1.50164227e+02 1.10854579e+06
     3.28247889e+05 1.95342267e+05 9.76153931e+04 5.81064317e+04
     3.48472685e+04 2.91591483e+04 1.73674986e+04 1.04273041e+04
     6.30922253e+03 8.75059964e+03 5.21694989e+03 3.13701782e+03
     1.90225250e+03 1.16311955e+03 4.77814865e+07 1.40483165e+07
     8.34702250e+06 4.14736151e+06 2.46313653e+06 1.47240427e+06
     1.22970655e+06 7.30196641e+05 4.36628701e+05 2.62841007e+05
     3.66270535e+05 2.17518714e+05 1.30152823e+05 7.84482709e+04
     4.76246733e+04 1.09609367e+05 6.51258832e+04 3.90090183e+04
     2.35520992e+04 1.43325296e+04 8.79122582e+03]
    


```python
from sklearn.linear_model import LinearRegression

lr = LinearRegression()
lr.fit(train_scaled, train_target)
```








```python
print(lr.score(train_scaled, train_target))
print(lr.score(test_scaled, test_target))
```

    1.0
    -358.85068551974916
    

# ë¦¿ì§€(ridge), ë¼ì˜(lasso)
- ì„ í˜•íšŒê·€ì— ê·œì œë¥¼ ì¶”ê°€í•œ ëª¨ë¸
- ì‚¬ì´í‚·ëŸ°ì—ì„œ ì œê³µ
- ë¦¿ì§€ì™€ ë¼ì˜ ëª¨ë¸ì„ ì‚¬ìš©í•  ë•Œ ê·œì œì˜ ì–‘(ê°•ë„) ì¡°ì ˆ ê°€ëŠ¥(í•˜ì´í¼íŒŒë¼ë¯¸í„° alpha)
    - alpha ê°’ì´ í¬ë©´ ê°•ë„ê°€ ì„¸ì§(ì ë‹¹í•œ ê°’ì„ ì°¾ì•„ì•¼ í•¨)

## ë¦¿ì§€ íšŒê·€(L2)
- ê³„ìˆ˜ë¥¼ ì œê³±í•œ ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ ê·œì œ ì ìš©
- ì¼ë°˜ì ìœ¼ë¡œ ì„ í˜¸í•¨

## ë¼ì˜ íšŒê·€(L1)
- ê³„ìˆ˜ì˜ ì ˆëŒ€ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ ê·œì œ ì ìš©
- ì•„ì˜ˆ 0ìœ¼ë¡œ ë§Œë“¤ ìˆ˜ ìˆìŒ


```python
# ê¸°ì¡´ ì„ í˜•íšŒê·€ ê³„ìˆ˜í™•ì¸
from sklearn.linear_model import LinearRegression

lr = LinearRegression()
lr.fit(train_input, train_target)
print(lr.score(train_input,train_target))
print(lr.score(test_input, test_target))
```

    0.9559326821885706
    0.8796419177546366
    


```python
w = lr.coef_
print(w)
b = lr.intercept_
print(b)
print('ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ê°’:', lr.predict([[8.4,2.11, 1.41]]))
print(f'y = [{(w[0]*8.4) + (w[1]*2.11) + (w[2]*1.41) + b}]')
```

    [ 9.07538153 69.46401443 38.00385678]
    -599.1708082981097
    ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ê°’: [-322.78309496]
    y = [-322.78309496037974]
    

### ì ê¹ ê°œë… í™•ì¸

#### ë‹¨ìˆœíšŒê·€ì‹
- ğ‘¦=ğ‘Šğ‘¥+ğ‘  
- yëŠ” ì •ë‹µ. xëŠ” íŠ¹ì„±
- W(ê¸°ìš¸ê¸°)ì™€ b(ì ˆí¸)ë¥¼ ì°¾ëŠ” ê²ƒ
- WëŠ” ê¸°ìš¸ê¸°, weight, ê³„ìˆ˜, coef ë‹¤ ê°™ì€ ì˜ë¯¸(íŠ¹ì„±ì— ê³±í•´ì¤„ ê°’)
- b íšŒê·€ì„ ì˜ ì‹œì‘ì (yì¶•ì˜ ì–´ë””ë¥¼ ê°€ë¥¼ ê²ƒì¸ì§€)

#### ë‹¤ì¤‘íšŒê·€ì‹
- ğ‘¦=(ğ‘Š1Ã—íŠ¹ì„±1)+(ğ‘Š2Ã—íŠ¹ì„±2)+(ğ‘Š3Ã—íŠ¹ì„±3) ... +ğ‘
- ë‹¨ìˆœíšŒê·€ì™€ ë™ì¼í•œ ê°œë…ì—ì„œ íŠ¹ì„±ì´ ì¶”ê°€ëœ ê²ƒ(ë‹¤ì–‘í•œ íŠ¹ì„±ìœ¼ë¡œ íšŒê·€ì„ ì„ ì°¾ëŠ” ê°œë…)
- ì°¨ì›ì´ 3ì°¨ì› ì´ìƒì´ ë˜ë©´ ê·¸ë˜í”„ í‘œí˜„ì´ ì–´ë ¤ìš´ ê²ƒ

### ë¦¿ì§€ íšŒê·€ í™•ì¸


```python
train_scaled[0]
```




    array([-1.01339619, -1.01007487, -1.01952321, -0.9549757 , -0.9496784 ,
           -0.95745849, -0.93942079, -0.94342509, -0.94100107, -0.88757122,
           -0.88399964, -0.89100599, -0.87785292, -0.88311456, -0.88430909,
           -0.8691891 , -0.87259422, -0.87147928, -0.86603533, -0.82233944,
           -0.82171953, -0.8280588 , -0.81928269, -0.82512549, -0.8278857 ,
           -0.81486775, -0.82006923, -0.82177279, -0.82010716, -0.80835934,
           -0.81274154, -0.81321125, -0.8098514 , -0.80275974, -0.7637909 ,
           -0.76597773, -0.77150714, -0.76668667, -0.77246614, -0.77577893,
           -0.76571689, -0.77162398, -0.77472752, -0.77517751, -0.76290623,
           -0.76877311, -0.77148634, -0.77113383, -0.767785  , -0.75814062,
           -0.76376113, -0.76586966, -0.76449499, -0.75967179, -0.75143746])




```python
# ìŠ¤ì¼€ì¼ë§ëœ ë°ì´í„°ì…‹ìœ¼ë¡œ ë¦¿ì§€íšŒê·€ í™•ì¸
from sklearn.linear_model import Ridge

ridge = Ridge()
ridge.fit(train_scaled, train_target)
print(ridge.score(train_scaled,train_target))
print(ridge.score(test_scaled, test_target))
```

    0.9896101671037343
    0.9790693977615387
    


```python
rw = ridge.coef_
print(rw)
rb = ridge.intercept_
print(rb)

print('ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ê°’:', ridge.predict([[-1.01339619, -1.01007487, -1.01952321, -0.9549757 , -0.9496784 ,
       -0.95745849, -0.93942079, -0.94342509, -0.94100107, -0.88757122,
       -0.88399964, -0.89100599, -0.87785292, -0.88311456, -0.88430909,
       -0.8691891 , -0.87259422, -0.87147928, -0.86603533, -0.82233944,
       -0.82171953, -0.8280588 , -0.81928269, -0.82512549, -0.8278857 ,
       -0.81486775, -0.82006923, -0.82177279, -0.82010716, -0.80835934,
       -0.81274154, -0.81321125, -0.8098514 , -0.80275974, -0.7637909 ,
       -0.76597773, -0.77150714, -0.76668667, -0.77246614, -0.77577893,
       -0.76571689, -0.77162398, -0.77472752, -0.77517751, -0.76290623,
       -0.76877311, -0.77148634, -0.77113383, -0.767785  , -0.75814062,
       -0.76376113, -0.76586966, -0.76449499, -0.75967179, -0.75143746]]))
y = 0
i = 0
for data in train_scaled[0]:
    y += rw[i] * data
    i += 1
y += rb
print(f'y =[{y}]')
```

    [18.75202605  9.99048537  9.64586193 17.278557   14.42089598 12.69251285
     12.34283964 10.88252862 12.55963482 12.93825844 12.67925897  9.12136175
     12.49327194  9.02641662  8.39716922 12.21409663  8.99564455  8.85968975
     11.68602892  7.48294042  8.98610839  3.37199818 10.27381252  4.61786228
      1.60700275 11.21975321  5.66171476  2.9808368   3.17359806 11.72544455
      6.40554378  4.19129005  5.06384222  8.89201309  1.89344091  4.81186299
     -2.91832747  7.38733861 -0.51038117 -5.91335297  9.5029666   1.56464851
     -3.66645267 -6.13031213 11.06068777  3.21356622 -1.71089861 -3.65107495
     -2.63704498 11.98418393  4.3636902  -0.11776857 -1.40420516  0.45174316
      5.29453248]
    400.8333333333333
    ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ê°’: [89.5482514]
    y =[89.54825137626369]
    

##### ê²°ê³¼
- ì„ í˜• íšŒê·€ì—ì„œ 0.99ì˜€ë˜ í›ˆë ¨ ë°ì´í„°ì…‹ì— ëŒ€í•œ ì ìˆ˜ê°€ ë‚®ì•„ì¡ŒìŒ
- í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì˜ ì ìˆ˜ê°€ ìœ ì˜ë¯¸í•œ ì •ë„ë¡œ ì¡°ì •ë¨

### ì ë‹¹í•œ alphaê°’ì„ ì°¾ëŠ” ë°©ë²•
- alphaê°’ì— ëŒ€í•œ $R^2$ ê°’ì˜ ê·¸ë˜í”„ ê·¸ë ¤ë³´ê¸°
- í›ˆë ¨ ë°ì´í„°ì…‹ê³¼ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì…‹ì˜ ì ìˆ˜ê°€ ê°€ì¥ ê°€ê¹Œìš´ ì§€ì ì´ ìµœì  alphaê°’


```python
import matplotlib.pyplot as plt

train_score = []
test_score = []
alpha_list = [0.001,0.01,0.1,1,10,100] # ì ìš©í•´ë³¼ alphaê°’ ë¦¬ìŠ¤íŠ¸
for alpha in alpha_list:
    # ë¦¿ì§€ ëª¨ë¸ ìƒì„±
    ridge = Ridge(alpha=alpha)
    # ë¦¿ì§€ ëª¨ë¸ í›ˆë ¨
    ridge.fit(train_scaled, train_target)
    # í›ˆë ¨ ì ìˆ˜ì™€ í…ŒìŠ¤íŠ¸ ì ìˆ˜ ì €ì¥
    train_score.append(ridge.score(train_scaled, train_target))
    test_score.append(ridge.score(test_scaled,test_target))
```


```python
train_score
```




    [0.9930455252088248,
     0.991780998125052,
     0.9903815817570367,
     0.9896101671037343,
     0.988728468997471,
     0.9841843235774494]




```python
test_score
```




    [0.9569388961567329,
     0.9800187936871725,
     0.9827976465386928,
     0.9790693977615387,
     0.9725329582461569,
     0.9627042641050291]




```python
# ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
plt.plot(alpha_list, train_score) # alphaë¦¬ìŠ¤íŠ¸ì˜ ê°’ì´ ì‘ìœ¼ë¯€ë¡œ ê·¸ë˜í”„ ì™¼ìª½ì´ ë„ˆë¬´ ì´˜ì´˜í•¨
plt.plot(alpha_list, test_score)

plt.xlabel('alpha')
plt.ylabel('R^2')

plt.show()
```


    
<img src = /assets/images/1week/2_03_íŠ¹ì„±ê³µí•™ê³¼ ê·œì œ_ê°œì¸í•™ìŠµ_files/2_03_íŠ¹ì„±ê³µí•™ê³¼ ê·œì œ_ê°œì¸í•™ìŠµ_60_0.png>
    



```python
print(alpha_list)
print(np.log10(alpha_list))
```

    [0.001, 0.01, 0.1, 1, 10, 100]
    [-3. -2. -1.  0.  1.  2.]
    


```python
plt.plot(np.log10(alpha_list), train_score)
plt.plot(np.log10(alpha_list), test_score)
plt.xlabel('alpha')
plt.ylabel('R^2')
plt.show()
```


    
<img src = /assets/images/1week/2_03_íŠ¹ì„±ê³µí•™ê³¼ ê·œì œ_ê°œì¸í•™ìŠµ_files/2_03_íŠ¹ì„±ê³µí•™ê³¼ ê·œì œ_ê°œì¸í•™ìŠµ_62_0.png>
    


```python
ridge = Ridge(alpha=0.1)
ridge.fit(train_scaled, train_target)

print(ridge.score(train_scaled, train_target))
print(ridge.score(test_scaled, test_target))
```

    0.9903815817570367
    0.9827976465386928
    

##### ê²°ê³¼
- í›ˆë ¨ ë°ì´í„°ì…‹ê³¼ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì˜ ì ìˆ˜ê°€ ëª¨ë‘ ë†’ìŒ
- ê³¼ëŒ€ì í•©ê³¼ ê³¼ì†Œì í•© ì‚¬ì´ì—ì„œ ê· í˜•ì„ ë§ì¶”ê³  ìˆë‹¤ê³  ë³¼ ìˆ˜ ìˆìŒ

### ë¼ì˜ íšŒê·€ í™•ì¸
- ë¦¿ì§€ë¥¼ ì‚¬ìš©í•  ë•Œì™€ ì‚¬ìš©ë²•ì€ ë¹„ìŠ·


```python
from sklearn.linear_model import Lasso

lasso = Lasso()
lasso.fit(train_scaled, train_target)
print(lasso.score(train_scaled, train_target))
print(lasso.score(test_scaled, test_target))
```

    0.989789897208096
    0.9800593698421883
    

##### ê²°ê³¼
- ì ìˆ˜ê°€ ë¦¿ì§€íšŒê·€ë§Œí¼ ì¢‹ìŒ
- alphaê°’ì„ ë³€ê²½í•˜ì—¬ ë¼ì˜ ê·œì œë¥¼ ì ìš©í•œ ê²°ê³¼ë¥¼ ì¡°ì •í•  ìˆ˜ ìˆë‹¤.


```python
import matplotlib.pyplot as plt

train_score = []
test_score = []
alpha_list = [0.001, 0.01, 0.1, 1, 10, 100] # ì ìš©í•´ë³¼ alphaê°’ ë¦¬ìŠ¤íŠ¸
for alpha in alpha_list:
    # ë¼ì˜ ëª¨ë¸ì„ ìƒì„±
    lasso = Lasso(alpha=alpha)
    # ë¼ì˜ ëª¨ë¸ì„ í›ˆë ¨
    lasso.fit(train_scaled, train_target)
    # í›ˆë ¨ ì ìˆ˜ì™€ í…ŒìŠ¤íŠ¸ ì ìˆ˜ ì €ì¥
    train_score.append(lasso.score(train_scaled, train_target))
    test_score.append(lasso.score(test_scaled, test_target))
```

    /usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.336e+04, tolerance: 5.183e+02
      model = cd_fast.enet_coordinate_descent(
    /usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.025e+04, tolerance: 5.183e+02
      model = cd_fast.enet_coordinate_descent(
    /usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.062e+02, tolerance: 5.183e+02
      model = cd_fast.enet_coordinate_descent(
    

- ë°œìƒí•œ ê²½ê³ ëŠ” ë¼ì˜ ëª¨ë¸ ë™ì‘ ì‹œ ìµœì  ê³„ìˆ˜ë¥¼ ì°¾ê¸°ìœ„í•´ ë°˜ë³µ ìˆ˜í–‰ì„ í•˜ëŠ”ë° íšŸìˆ˜ ë¶€ì¡± ì‹œ ë°œìƒí•¨
- `lasso = Lasso(alpha=alpha, max_iter=10000)` max_iterì˜µì…˜ì„ ì¶”ê°€í•  ìˆ˜ ìˆìŒ(ì—¬ê¸°ì„  í° ì˜ë¯¸ ì—†ìŒ)


```python
plt.plot(np.log10(alpha_list), train_score)
plt.plot(np.log10(alpha_list), test_score)
plt.xlabel('alpha')
plt.ylabel('R^2')
plt.show()
```


    
<img src = "/assets/images/1week/2_03_íŠ¹ì„±ê³µí•™ê³¼ ê·œì œ_ê°œì¸í•™ìŠµ_files/2_03_íŠ¹ì„±ê³µí•™ê³¼ ê·œì œ_ê°œì¸í•™ìŠµ_71_0.png">
    



```python
print(lasso.score(train_scaled, train_target))
print(lasso.score(test_scaled, test_target))
```

    0.9078632190121442
    0.9089071866576974
    


```python
lasso = Lasso(alpha=10)
lasso.fit(train_scaled, train_target)

print(lasso.score(train_scaled, train_target))
print(lasso.score(test_scaled, test_target))
```

    0.9888067471131867
    0.9824470598706695
    


```python
lw = lasso.coef_
print(lw)
lb = lasso.intercept_
print(lb)

print('ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ê°’:', lasso.predict([[-1.01339619, -1.01007487, -1.01952321, -0.9549757 , -0.9496784 ,
       -0.95745849, -0.93942079, -0.94342509, -0.94100107, -0.88757122,
       -0.88399964, -0.89100599, -0.87785292, -0.88311456, -0.88430909,
       -0.8691891 , -0.87259422, -0.87147928, -0.86603533, -0.82233944,
       -0.82171953, -0.8280588 , -0.81928269, -0.82512549, -0.8278857 ,
       -0.81486775, -0.82006923, -0.82177279, -0.82010716, -0.80835934,
       -0.81274154, -0.81321125, -0.8098514 , -0.80275974, -0.7637909 ,
       -0.76597773, -0.77150714, -0.76668667, -0.77246614, -0.77577893,
       -0.76571689, -0.77162398, -0.77472752, -0.77517751, -0.76290623,
       -0.76877311, -0.77148634, -0.77113383, -0.767785  , -0.75814062,
       -0.76376113, -0.76586966, -0.76449499, -0.75967179, -0.75143746]]))
y = 0
i = 0
for data in train_scaled[0]:
    y += lw[i] * data
    i += 1
y += lb
print(f'y =[{y}]')
```

    [ 0.          0.          0.         12.14852453 55.44856399 42.23100799
      0.          0.         13.70596191  0.         43.2185952   5.7033775
     47.46254536  7.42309425 11.85823365  0.          0.         13.53038193
     21.22111356  0.          0.          0.          0.          0.
      0.         18.66993032  0.          0.          0.         15.81041778
      0.          0.          0.          0.          0.          0.
      0.          0.          0.          0.          0.          0.
      0.          0.         18.14672268  0.          0.          0.
      0.         15.51272953  0.          0.          0.          0.
      0.        ]
    400.8333333333333
    ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ê°’: [97.47905279]
    y =[97.47905338741793]
    

##### ê²°ê³¼
- ëª¨ë¸ì˜ í›ˆë ¨ì´ ì˜ ëœ ê²ƒìœ¼ë¡œ ë³´ì„
- ë¦¿ì§€ì™€ ë¼ì˜ ëª¨ë‘ ê³¼ëŒ€ì í•©ì„ ì˜ ì–µì œí•˜ê³  í…ŒìŠ¤íŠ¸ ì„±ëŠ¥ì„ í¬ê²Œ ë†’ì¼ ìˆ˜ ìˆìŒ


```python
# ë¼ì˜ ëª¨ë¸ì€ ê³„ìˆ˜ë¥¼ 0ìœ¼ë¡œ ë§Œë“¤ ìˆ˜ ìˆìŒ(coef_ê²Œ ì €ì¥ë˜ì–´ ìˆìŒ)
print(np.sum(lasso.coef_ == 0)) # ë¼ì˜ ëª¨ë¸ì—ì„œ ê³„ìˆ˜ê°€ 0ì¸ ê°œìˆ˜
```

- ë¼ì˜ ëª¨ë¸ì— 55ê°œì˜ íŠ¹ì„±ì„ ì£¼ì…í–ˆìœ¼ë‚˜ 15ê°œë§Œ ì‚¬ìš©ë˜ì–´ì§
- ë¼ì˜ë¥¼ ì´ìš©í•˜ì—¬ ìœ ìš©í•œ íŠ¹ì„±ì„ ì¶”ë ¤ë‚´ëŠ” ìš©ë„ë¡œë„ ì‚¬ìš© ê°€ëŠ¥
