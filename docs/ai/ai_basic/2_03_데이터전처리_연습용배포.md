# 기존 모델로 예측 결과 확인



```python
fish_length = [25.4, 26.3, 26.5, 29.0, 29.0, 29.7, 29.7, 30.0, 30.0, 30.7, 31.0, 31.0, 
                31.5, 32.0, 32.0, 32.0, 33.0, 33.0, 33.5, 33.5, 34.0, 34.0, 34.5, 35.0, 
                35.0, 35.0, 35.0, 36.0, 36.0, 37.0, 38.5, 38.5, 39.5, 41.0, 41.0, 9.8, 
                10.5, 10.6, 11.0, 11.2, 11.3, 11.8, 11.8, 12.0, 12.2, 12.4, 13.0, 14.3, 15.0]
fish_weight = [242.0, 290.0, 340.0, 363.0, 430.0, 450.0, 500.0, 390.0, 450.0, 500.0, 475.0, 500.0, 
                500.0, 340.0, 600.0, 600.0, 700.0, 700.0, 610.0, 650.0, 575.0, 685.0, 620.0, 680.0, 
                700.0, 725.0, 720.0, 714.0, 850.0, 1000.0, 920.0, 955.0, 925.0, 975.0, 950.0, 6.7, 
                7.5, 7.0, 9.7, 9.8, 8.7, 10.0, 9.9, 9.8, 12.2, 13.4, 12.2, 19.7, 19.9]

# 2차원 데이터로 변환(각각의 데이터는 샘플이라 부름)
fish_data = [[l, w] for l, w in zip(fish_length, fish_weight)]
fish_target = [1]*35 + [0]*14
```


```python
# 넘파이 모듈 import하기
import numpy as np 

# 생선 데이터로 numpy 배열 생성(input, target)
input_arr = 
target_arr = 

# 랜덤한 index 구하기
 # 항상 동일한 결과를 위해 지정함


# 넘파이의 배열 인덱싱으로 훈련데이터와 테스트 데이터 나누기

```


```python
# KNeighborsClassifier 임포트하기


# KNeighborsClassifier 객체 생성


# 학습하기


# 모델 정확도 평가 점수 확인

```




    1.0




```python
kn.predict([[25,150]]) 
```




    array([0])




```python
# 시각화
import matplotlib.pyplot as plt

plt.scatter(train_input[:, 0], train_input[:, 1])
plt.scatter(test_input[:, 0], test_input[:, 1])
plt.scatter(25, 150, marker='^') # 분류 대상 표시
plt.xlabel('length')
plt.ylabel('weight')
plt.show()
```


    
![png](2_03_%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%A0%84%EC%B2%98%EB%A6%AC_%EC%97%B0%EC%8A%B5%EC%9A%A9%EB%B0%B0%ED%8F%AC_files/2_03_%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%A0%84%EC%B2%98%EB%A6%AC_%EC%97%B0%EC%8A%B5%EC%9A%A9%EB%B0%B0%ED%8F%AC_5_0.png)
    


- 그래프로 확인해보면 25cm에 150g이면 도미로 분류해야 하는데 빙어로 분류됨
- 왜일까?

# 넘파이를 활용하여 다시 준비하기

- 훈련 데이터를 만드는 작업에 넘파이를 활용


```python
fish_length = [25.4, 26.3, 26.5, 29.0, 29.0, 29.7, 29.7, 30.0, 30.0, 30.7, 31.0, 31.0, 
                31.5, 32.0, 32.0, 32.0, 33.0, 33.0, 33.5, 33.5, 34.0, 34.0, 34.5, 35.0, 
                35.0, 35.0, 35.0, 36.0, 36.0, 37.0, 38.5, 38.5, 39.5, 41.0, 41.0, 9.8, 
                10.5, 10.6, 11.0, 11.2, 11.3, 11.8, 11.8, 12.0, 12.2, 12.4, 13.0, 14.3, 15.0]
fish_weight = [242.0, 290.0, 340.0, 363.0, 430.0, 450.0, 500.0, 390.0, 450.0, 500.0, 475.0, 500.0, 
                500.0, 340.0, 600.0, 600.0, 700.0, 700.0, 610.0, 650.0, 575.0, 685.0, 620.0, 680.0, 
                700.0, 725.0, 720.0, 714.0, 850.0, 1000.0, 920.0, 955.0, 925.0, 975.0, 950.0, 6.7, 
                7.5, 7.0, 9.7, 9.8, 8.7, 10.0, 9.9, 9.8, 12.2, 13.4, 12.2, 19.7, 19.9]
```


```python
# 넘파이 모듈 임포트

```


```python
# 같은 인덱스끼리 묶어줌
np.column_stack(([1,2,3], [4,5,6]))
```




    array([[1, 4],
           [2, 5],
           [3, 6]])




```python
# column_stack()함수를 활용하여 생선 길이데이타와 무게 데이터를 함침
fish_data = 
fish_data[:5]
```




    array([[ 25.4, 242. ],
           [ 26.3, 290. ],
           [ 26.5, 340. ],
           [ 29. , 363. ],
           [ 29. , 430. ]])




```python
# 1또는 0을 가지는 넘파이배열을 생성하는 함수
np.ones(5), np.zeros(5)
```




    (array([1., 1., 1., 1., 1.]), array([0., 0., 0., 0., 0.]))




```python
# concatenate()함수는 넘파이 배열을 이어붙임
fish_target = 
```


```python
fish_target
```




    array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
           1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])



### 데이터 나누기
- 사이킷런에서 제공하는 함수를 활용하여 훈련/테스트 데이터를 분할


```python
# train_test_split함수 임포트
```


```python
# train_test_split함수를 사용하여 데이터셋 나누기
```


```python
# 나누어진 데이터셋의 모양 확인
train_input.shape, test_input.shape, train_target.shape, test_target.shape
```




    ((36, 2), (13, 2), (36,), (13,))




```python
test_target
```




    array([1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.])




```python
# stratify=fish_target 옵션을 추가하여 train_test_split함수로 데이터셋 분할하기
# 타겟에 들어있는 값들의 비율로 분할됨


```


```python
test_target
```




    array([0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.])




```python
# KNeighborsClassifier 임포트하기


# KNeighborsClassifier 객체 생성


# 학습하기


# 모델 정확도 평가 점수 확인

```




    1.0




```python
# 25,150 예측 하기
kn.predict([[25,150]]) 
```




    array([0.])



- 여전히 결과가 빙어로 처리된다.


```python
# [25,150]의 이웃 개수 확인
distances, indexes = 
print(distances)
print(indexes)
```

    [[ 92.00086956 130.48375378 130.73859415 138.32150953 138.39320793]]
    [[21 33 19 30  1]]
    


```python
# 시각화 하여 확인
import matplotlib.pyplot as plt
plt.scatter(train_input[:,0], train_input[:,1])
plt.scatter(train_input[indexes,0], train_input[indexes,1], marker='D')
plt.scatter(25, 150, marker='^')
plt.xlabel('length')
plt.ylabel('weight')
plt.show()
```


    
![png](2_03_%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%A0%84%EC%B2%98%EB%A6%AC_%EC%97%B0%EC%8A%B5%EC%9A%A9%EB%B0%B0%ED%8F%AC_files/2_03_%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%A0%84%EC%B2%98%EB%A6%AC_%EC%97%B0%EC%8A%B5%EC%9A%A9%EB%B0%B0%ED%8F%AC_26_0.png)
    


- 왜 더 가까운 도미가 이웃이 아니라 빙어가 이웃으로 판단되는걸까?

- k-최근접 이웃 알고리즘은 주변의 샘플 중 가까운 것이 다수인 클래스를 예측
- 이웃들 중 가장 가까운 5개를 찾아 분류 결과를 예측함
- 가깝다라는 기준을 distances로 확인할 수 있는데 거리 비율이 이상함
- [ 92.00086956 130.48375378 130.73859415 138.32150953 138.39320793]
- x축 범위 (10 ~ 40)
- y축 범위 (0 ~ 1000)
- y축으로 조금만 떨어져도 크게 달라지는 것


```python
plt.scatter(train_input[:,0], train_input[:,1])
plt.scatter(25, 150, marker='^')
plt.scatter(train_input[indexes,0], train_input[indexes,1], marker='D')
plt.xlim((0, 1000)) # x축의 기준범위 변경. ylim은 y축의 기준범위 변경
plt.xlabel('length')
plt.ylabel('weight')
plt.show()
```


    
![png](2_03_%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%A0%84%EC%B2%98%EB%A6%AC_%EC%97%B0%EC%8A%B5%EC%9A%A9%EB%B0%B0%ED%8F%AC_files/2_03_%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%A0%84%EC%B2%98%EB%A6%AC_%EC%97%B0%EC%8A%B5%EC%9A%A9%EB%B0%B0%ED%8F%AC_28_0.png)
    


- 위와 같이 만들면 생선의 무게가 분류 기준이 될 수 있음
- 길이와 무게가 서로 값의 범위가 달라서 생긴 문제(Scale이 다름)
- 데이터를 표현하는 기준이 다르면 결과가 올바르지 않음
- 거리기반의 알고리즘인 kNN뿐만 아니라 모든 알고리즘에서 영향이 있을 수 있음

#### 따라서 샘플들의 값을 일정한 기준으로 맞출 필요가 있음

# 데이터 전처리
- 모델의 결과가 유의미 하기 위해 반드시 데이터 전처리 과정이 필요
- 앞서 확인한 것과 같이 모델을 통한 결과에 문제가 발생할 수 있음
- 이러한 문제를 덜 발생시키도록 데이터의 전처리는 매우 중요함
- 전처리는 일반적으로 표준점수(standard score)를 사용(z점수라고도 함)

- 표준점수는 각 특성값이 평균에서 표준편차의 몇 배만큼 떨어져 있는지를 나타냄
- 표준점수를 이용하면 특성값의 크기를 동일한 조건으로 만들어 비교 가능


```python
# 분산: 데이터에서 평균을 뺀 값을 모두 제곱한 후 평균값
# 표준편차: 분산의 제곱근. 데이터가 분산된 정도를 의미
# 표준점수: 데이터가 원점에서 얼마만큼의 표준편차만큼 떨어져 있는가를 나타내는 값

# 표준점수 구하기
mean =  #평균. axis=0은 행을 축으로 함
std =  # 표준편차. axis=0은 행을 축으로 함
print(mean, std)
```

    [ 27.29722222 454.09722222] [  9.98244253 323.29893931]
    

#### 브로드캐스팅
- 넘파이 배열 연산을 할 때 모든 행을 대상으로 진행되는 것을 말함
- 값이 하나인 평균과 표준편차가 넘파이 배열의 모든 행과 열에 연산이 적용되는 것


```python
train_scaled = (train_input - mean) / std # 넘파이 배열 연산은 모든 행을 대상으로 계산됨
print(train_scaled)
```

    [[ 0.24070039  0.14198246]
     [-1.51237757 -1.36683783]
     [ 0.5712808   0.76060496]
     [-1.60253587 -1.37766373]
     [ 1.22242404  1.45655528]
     [ 0.17057727 -0.07453542]
     [ 0.87180845  0.80390854]
     [ 0.87180845  1.22457184]
     [ 0.37092904  0.06465464]
     [ 0.77163257  0.82246721]
     [ 0.97198434  1.68853872]
     [-1.61255346 -1.3742613 ]
     [ 0.72154463  0.51315596]
     [-1.53241275 -1.3742613 ]
     [ 0.17057727 -0.28177396]
     [ 0.5712808   0.76060496]
     [ 0.34087627  0.14198246]
     [ 1.12224816  1.54934866]
     [ 0.62136874  0.60594934]
     [-1.30200822 -1.34363949]
     [ 0.42101698  0.14198246]
     [-0.19005591 -0.65604058]
     [-1.75279969 -1.38384995]
     [ 0.47110492  0.45129371]
     [-1.68267658 -1.38137546]
     [ 0.62136874  0.48222484]
     [-1.67265899 -1.38292202]
     [ 0.77163257  0.76060496]
     [ 0.47110492  0.45129371]
     [ 0.77163257  0.83793278]
     [-1.43223687 -1.36683783]
     [ 0.27075315 -0.01267317]
     [ 0.47110492 -0.35291555]
     [-1.2318851  -1.34302087]
     [ 0.27075315 -0.19825992]
     [ 1.37268787  1.61121091]]
    


```python
# 표준 점수로 변환된 train_scaled를 시각화
plt.scatter(train_scaled[:,0], train_scaled[:,1])
plt.scatter(25, 150, marker='^')
plt.xlabel('length')
plt.ylabel('weight')
plt.show()
```


    
![png](2_03_%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%A0%84%EC%B2%98%EB%A6%AC_%EC%97%B0%EC%8A%B5%EC%9A%A9%EB%B0%B0%ED%8F%AC_files/2_03_%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%A0%84%EC%B2%98%EB%A6%AC_%EC%97%B0%EC%8A%B5%EC%9A%A9%EB%B0%B0%ED%8F%AC_34_0.png)
    


- 값의 범위가 달라져서 25, 150역시 스케일링 필요
- 훈련세트의 mean, std값으로 스케일링해야 함


```python
# [25, 150]를 훈련데이터셋의 스케일링과 동일하게 변경
new = 
new
```




    array([-0.23012627, -0.94060693])




```python
plt.scatter(train_scaled[:,0], train_scaled[:,1])
plt.scatter(new[0], new[1], marker='^')
plt.xlabel('length')
plt.ylabel('weight')
plt.show()
```


    
![png](2_03_%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%A0%84%EC%B2%98%EB%A6%AC_%EC%97%B0%EC%8A%B5%EC%9A%A9%EB%B0%B0%ED%8F%AC_files/2_03_%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%A0%84%EC%B2%98%EB%A6%AC_%EC%97%B0%EC%8A%B5%EC%9A%A9%EB%B0%B0%ED%8F%AC_37_0.png)
    


- 스케일링 하기 전과 형태가 거의 동일함.
- 값의 크기만 일정하게 변환되었음

### 다시 모델을 정의하여 테스트


```python
# KNeighborsClassifier 임포트하기


# KNeighborsClassifier 객체 생성


# 학습하기


# 모델 정확도 평가 점수 확인
# 테스트 데이터(test_input)도 훈련데이터로 만든 기준으로 스케일링
test_scaled = 
kn.score(test_scaled, test_target)
```




    1.0




```python
# 25, 150을 스케일링한 값으로 예측 테스트
print(kn.predict([new]))
```

    [1.]
    


```python
# 이웃 정보 확인하기
distances, indexes = kn.kneighbors([new])
plt.scatter(train_scaled[:,0], train_scaled[:,1])
plt.scatter(new[0], new[1], marker='^')
plt.scatter(train_scaled[indexes,0], train_scaled[indexes,1], marker='D')
plt.xlabel('length')
plt.ylabel('weight')
plt.show()
```


    
![png](2_03_%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%A0%84%EC%B2%98%EB%A6%AC_%EC%97%B0%EC%8A%B5%EC%9A%A9%EB%B0%B0%ED%8F%AC_files/2_03_%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%A0%84%EC%B2%98%EB%A6%AC_%EC%97%B0%EC%8A%B5%EC%9A%A9%EB%B0%B0%ED%8F%AC_42_0.png)
    


### 여기까지 정리하기
